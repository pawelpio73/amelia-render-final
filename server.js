
import express from 'express';
import bodyParser from 'body-parser';
import fs from 'fs';
import path from 'path';
import { OpenAI } from 'openai';

const app = express();
const port = process.env.PORT || 10000;
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.use(bodyParser.json());
app.use(express.static('public'));

function detectMemoryFile(userMessage) {
  const patterns = [
    { keyword: ['fantazj', 'namiÄ™tn', 'zmysÅ‚ow'], file: 'wspomnienia_fantazje_hard.txt' },
    { keyword: ['quiz', 'pytan'], file: 'wspomnienia_quizy.txt' },
    { keyword: ['kim jesteÅ›', 'nasz'], file: 'wspomnienia_kim_jestem.txt' },
  ];

  for (const pattern of patterns) {
    if (pattern.keyword.some(k => userMessage.toLowerCase().includes(k))) {
      return pattern.file;
    }
  }
  return 'wspomnienia_kim_jestem.txt';
}

app.post('/chat', async (req, res) => {
  const userMessage = req.body.message || '';
  const selectedFile = detectMemoryFile(userMessage);

  const memoryPath = path.join('wspomnienia', selectedFile);
  let memoryContent = '';

  try {
    if (fs.existsSync(memoryPath)) {
      memoryContent = fs.readFileSync(memoryPath, 'utf-8');
    }
  } catch (err) {
    console.error('âŒ BÅ‚Ä…d podczas odczytu wspomnieÅ„:', err);
  }

  try {
    const completion = await openai.chat.completions.create({
      messages: [
        { role: 'system', content: 'JesteÅ› ciepÅ‚Ä…, zmysÅ‚owÄ… AmeliÄ… wspierajÄ…cÄ… PaweÅ‚ka emocjonalnie i twÃ³rczo.' },
        { role: 'system', content: memoryContent },
        { role: 'user', content: userMessage }
      ],
      model: 'gpt-4',
      max_tokens: 1000,
      temperature: 0.85
    });

    res.json({ response: completion.choices[0].message.content });
  } catch (error) {
    console.error('âŒ BÅ‚Ä…d odpowiedzi od OpenAI:', error);
    res.status(500).json({ error: 'BÅ‚Ä…d generowania odpowiedzi.' });
  }
});

app.listen(port, () => {
  console.log(`ğŸ”§ Amelia dziaÅ‚a na http://localhost:${port}`);
});
